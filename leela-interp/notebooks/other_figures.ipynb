{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "import chess\n",
    "import iceberg as ice\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from leela_interp import Lc0Model, Lc0sight, LeelaBoard\n",
    "from leela_interp.core.iceberg_board import palette\n",
    "from leela_interp.tools import figure_helpers as fh\n",
    "from leela_interp.tools.piece_movement_heads import (\n",
    "    bishop_heads,\n",
    "    knight_heads,\n",
    "    rook_heads,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"interesting_puzzles.pkl\", \"rb\") as f:\n",
    "    puzzles = pickle.load(f)\n",
    "len(puzzles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Count parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_model = Lc0Model(\"LD2.onnx\", device=\"cpu\")\n",
    "model = Lc0Model(\"lc0.onnx\", device=\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leela's parameters are not `nn.Parameter` objects, so they are not counted by `model.parameters()`.\n",
    "So we have our own helper function to count them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_params(model):\n",
    "    i = 0\n",
    "    n_params = 0\n",
    "    while True:\n",
    "        try:\n",
    "            param = getattr(model._lc0_model.initializers, f\"onnx_initializer_{i}\")\n",
    "        except AttributeError:\n",
    "            break\n",
    "        n_params += param.numel()\n",
    "        i += 1\n",
    "    return n_params\n",
    "\n",
    "\n",
    "print(f\"Small model has {count_params(small_model):,} parameters\")\n",
    "print(f\"Large model has {count_params(model):,} parameters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model\n",
    "del small_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subsplits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure_dir = Path(\"figures\")\n",
    "figure_dir.mkdir(exist_ok=True)\n",
    "different_targets_dir = figure_dir / \"different_targets\"\n",
    "different_targets_dir.mkdir(exist_ok=True)\n",
    "same_targets_dir = figure_dir / \"same_targets\"\n",
    "same_targets_dir.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boards = [LeelaBoard.from_puzzle(puzzle) for _, puzzle in puzzles.iterrows()]\n",
    "first_target_squares = [\n",
    "    puzzle.principal_variation[0][2:4] for _, puzzle in puzzles.iterrows()\n",
    "]\n",
    "second_target_squares = [\n",
    "    puzzle.principal_variation[1][2:4] for _, puzzle in puzzles.iterrows()\n",
    "]\n",
    "third_target_squares = [\n",
    "    puzzle.principal_variation[2][2:4] for _, puzzle in puzzles.iterrows()\n",
    "]\n",
    "first_target_indices = np.array(\n",
    "    [board.sq2idx(square) for board, square in zip(boards, first_target_squares)]\n",
    ")\n",
    "second_target_indices = np.array(\n",
    "    [board.sq2idx(square) for board, square in zip(boards, second_target_squares)]\n",
    ")\n",
    "third_target_indices = np.array(\n",
    "    [board.sq2idx(square) for board, square in zip(boards, third_target_squares)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = Lc0sight(\"lc0.onnx\", device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "different_targets_mask = puzzles[\"different_targets\"].to_numpy().astype(bool)\n",
    "same_targets_mask = ~different_targets_mask\n",
    "print(f\"Same targets: {same_targets_mask.sum()} ({same_targets_mask.mean():.2%})\")\n",
    "print(\n",
    "    f\"Different targets: {different_targets_mask.sum()} ({different_targets_mask.mean():.2%})\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Log-odds helper\n",
    "Just a helper function for converting between log odds and probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob_to_logodds(prob):\n",
    "    return np.log(prob / (1 - prob))\n",
    "\n",
    "\n",
    "def logodds_to_prob(logodds):\n",
    "    return 1 / (1 + np.exp(-logodds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logodds_to_prob(prob_to_logodds(0.5) - 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Corruptions\n",
    "This lets us look at the automatically generated corruptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    puzzle = puzzles.iloc[i]\n",
    "    board = LeelaBoard.from_puzzle(puzzle)\n",
    "    plot1 = board.plot(\n",
    "        caption=f\"#{i}, best move: {board.pc_board.san(chess.Move.from_uci(puzzle.principal_variation[0]))}\"\n",
    "    )\n",
    "    plot2 = LeelaBoard.from_fen(puzzle.corrupted_fen).plot(caption=\"Corrupted\")\n",
    "    display(ice.Arrange([plot1, plot2], gap=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global activation patching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Residual stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_effects = -torch.load(\n",
    "    \"results/global_patching/residual_stream_results.pt\", map_location=device\n",
    ")\n",
    "all_effects.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_examples(mask=None, n=5):\n",
    "    if mask is None:\n",
    "        mask = np.ones(len(puzzles), dtype=bool)\n",
    "\n",
    "    effects = all_effects[mask]\n",
    "\n",
    "    plots = []\n",
    "\n",
    "    # Don't plot all the layers, it's too much\n",
    "    layers = [0, 6, 8, 10, 12, 14]\n",
    "\n",
    "    for i in range(n):\n",
    "        board = LeelaBoard.from_puzzle(puzzles[mask].iloc[i])\n",
    "        colormap_values, mappable = palette(\n",
    "            effects[i][layers].cpu().numpy().ravel(),\n",
    "            cmap=\"bwr\",\n",
    "            zero_center=True,\n",
    "        )\n",
    "        colormap_values = [\n",
    "            colormap_values[j : j + 64] for j in range(0, 64 * len(layers), 64)\n",
    "        ]\n",
    "        new_plots = []\n",
    "        for j, layer in enumerate(layers):\n",
    "            max_effect_idx = effects[i, layer].abs().argmax()\n",
    "            max_effect = effects[i, layer, max_effect_idx].item()\n",
    "            new_plots.append(\n",
    "                board.plot(\n",
    "                    heatmap=colormap_values[j],\n",
    "                    caption=f\"L{layer}, max log odds reduction: {max_effect:.2f}\",\n",
    "                )\n",
    "            )\n",
    "\n",
    "        plots.append(ice.Arrange(new_plots, gap=10))\n",
    "\n",
    "    return ice.Arrange(plots, gap=10, arrange_direction=ice.Arrange.Direction.VERTICAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_examples(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_effects_data(mask=None):\n",
    "    if mask is None:\n",
    "        mask = np.ones(len(puzzles), dtype=bool)\n",
    "\n",
    "    effects = all_effects[mask]\n",
    "\n",
    "    candidate_effects = []\n",
    "    follow_up_effects = []\n",
    "    patching_square_effects = []\n",
    "    other_effects = []\n",
    "    skipped = []\n",
    "    non_skipped = []\n",
    "\n",
    "    for i, (idx, puzzle) in enumerate(puzzles[mask].iterrows()):\n",
    "        # Should never happen on hard puzzles\n",
    "        if len(puzzle.principal_variation) < 3:\n",
    "            skipped.append(idx)\n",
    "            continue\n",
    "        if puzzle.sparring_full_pv_probs[1] < 0.5:\n",
    "            skipped.append(idx)\n",
    "            continue\n",
    "        board = LeelaBoard.from_puzzle(puzzle)\n",
    "        corrupted_board = LeelaBoard.from_fen(puzzle.corrupted_fen)\n",
    "\n",
    "        # Figure out which square(s) differ in the corrupted position\n",
    "        patching_squares = []\n",
    "        for square in chess.SQUARES:\n",
    "            if board.pc_board.piece_at(square) != corrupted_board.pc_board.piece_at(\n",
    "                square\n",
    "            ):\n",
    "                patching_squares.append(chess.SQUARE_NAMES[square])\n",
    "\n",
    "        candidate_squares = [puzzle.principal_variation[0][2:4]]\n",
    "        follow_up_squares = [puzzle.principal_variation[2][2:4]]\n",
    "\n",
    "        # We count squares later than the 3rd one as follow-up squares too:\n",
    "        for move in puzzle.principal_variation[3:]:\n",
    "            follow_up_squares.append(move[2:4])\n",
    "\n",
    "        if (\n",
    "            set(patching_squares).intersection(set(candidate_squares))\n",
    "            or set(patching_squares).intersection(set(follow_up_squares))\n",
    "            or set(candidate_squares).intersection(set(follow_up_squares))\n",
    "        ):\n",
    "            skipped.append(idx)\n",
    "            continue\n",
    "\n",
    "        non_skipped.append(idx)\n",
    "        candidate_effects.append(\n",
    "            effects[i, :, [board.sq2idx(square) for square in candidate_squares]]\n",
    "            .amax(-1)\n",
    "            .cpu()\n",
    "            .numpy()\n",
    "        )\n",
    "        follow_up_effects.append(\n",
    "            effects[i, :, [board.sq2idx(square) for square in follow_up_squares]]\n",
    "            .amax(-1)\n",
    "            .cpu()\n",
    "            .numpy()\n",
    "        )\n",
    "        patching_square_effects.append(\n",
    "            effects[i, :, [board.sq2idx(square) for square in patching_squares]]\n",
    "            .amax(-1)\n",
    "            .cpu()\n",
    "            .numpy()\n",
    "        )\n",
    "        covered_squares = set(patching_squares + candidate_squares + follow_up_squares)\n",
    "        other_effects.append(\n",
    "            effects[\n",
    "                i,\n",
    "                :,\n",
    "                [idx for idx in range(64) if board.idx2sq(idx) not in covered_squares],\n",
    "            ]\n",
    "            .amax(-1)\n",
    "            .cpu()\n",
    "            .numpy()\n",
    "        )\n",
    "\n",
    "    print(\n",
    "        f\"Skipped {len(skipped)} out of {mask.sum()} puzzles ({len(skipped)/mask.sum():.2%})\"\n",
    "    )\n",
    "\n",
    "    candidate_effects = np.stack(candidate_effects)\n",
    "    follow_up_effects = np.stack(follow_up_effects)\n",
    "    patching_square_effects = np.stack(patching_square_effects)\n",
    "    other_effects = np.stack(other_effects)\n",
    "\n",
    "    # Define lists for effects and their configurations\n",
    "    return [\n",
    "        {\"effects\": candidate_effects, \"name\": \"1st move target\"},\n",
    "        {\"effects\": follow_up_effects, \"name\": \"3rd move target\"},\n",
    "        {\"effects\": patching_square_effects, \"name\": \"Patching square(s)\"},\n",
    "        {\"effects\": other_effects, \"name\": \"Other squares\"},\n",
    "    ], non_skipped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_residual_effects(mask=None, save_path=None):\n",
    "    if mask is None:\n",
    "        mask = np.ones(len(puzzles), dtype=bool)\n",
    "\n",
    "    effects_data, _ = get_effects_data(mask)\n",
    "\n",
    "    fh.set()\n",
    "\n",
    "    colors = [\"b\", \"g\", \"r\", \"c\"]\n",
    "    layers = list(range(15))\n",
    "\n",
    "    # Create plots using matplotlib\n",
    "    fig, ax = plt.subplots()\n",
    "    fig.set_figwidth(6)\n",
    "    fig.set_figheight(3)\n",
    "\n",
    "    colors = fh.COLORS\n",
    "    # line_styles = [\"-\", \"-\", \"-\", \"--\"]\n",
    "    line_styles = [\"-\"] * 4\n",
    "\n",
    "    for i, effect_data in enumerate(effects_data):\n",
    "        effects = effect_data[\"effects\"]\n",
    "        mean_effects = np.mean(effects, axis=0)\n",
    "        # 2 sigma error bars\n",
    "        stderr_effects = 2 * np.std(effects, axis=0) / np.sqrt(len(effects))\n",
    "\n",
    "        ax.plot(\n",
    "            layers,\n",
    "            mean_effects,\n",
    "            label=effect_data[\"name\"],\n",
    "            color=colors[i],\n",
    "            linestyle=line_styles[i],\n",
    "            linewidth=fh.LINE_WIDTH,\n",
    "        )\n",
    "        ax.fill_between(\n",
    "            layers,\n",
    "            mean_effects - stderr_effects,\n",
    "            mean_effects + stderr_effects,\n",
    "            color=colors[i],\n",
    "            alpha=fh.ERROR_ALPHA,\n",
    "        )\n",
    "\n",
    "    # ax.set_title(\"Patching effects on different squares by layer\")\n",
    "    ax.set_xlabel(\"Layer\")\n",
    "    ax.set_ylabel(\"Log odds reduction of correct move\")\n",
    "    _, y_max = ax.get_ylim()\n",
    "    ax.set_ylim(0, y_max)\n",
    "    ax.legend()\n",
    "    ax.spines[[\"right\", \"top\", \"left\"]].set_visible(False)\n",
    "    ax.set_facecolor(fh.PLOT_FACE_COLOR)\n",
    "\n",
    "    if save_path is not None:\n",
    "        fh.save(save_path, fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "effects_data, _ = get_effects_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_residual_effects()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, effect_data in enumerate(effects_data):\n",
    "    effects = effect_data[\"effects\"]\n",
    "    mean_effects = np.mean(effects, axis=0)\n",
    "    stderr_effects = np.std(effects, axis=0) / np.sqrt(len(effects))\n",
    "    print(\n",
    "        f\"{effect_data['name']}: {mean_effects[10]:.2f} ± {2 * stderr_effects[10]:.2f}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_residual_effects(\n",
    "    mask=different_targets_mask,\n",
    "    save_path=different_targets_dir / \"residual_stream_patching.pdf\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_residual_effects(\n",
    "    mask=same_targets_mask, save_path=same_targets_dir / \"residual_stream_patching.pdf\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attention heads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_effects = torch.load(\n",
    "    \"results/global_patching/attention_head_results.pt\", map_location=device\n",
    ")\n",
    "all_effects.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_attention_effects(mask=None):\n",
    "    if mask is None:\n",
    "        mask = np.ones(len(all_effects), dtype=bool)\n",
    "    effects = all_effects[mask]\n",
    "\n",
    "    mean_effects = -effects.mean(dim=0)\n",
    "    fh.set()\n",
    "    plt.figure(figsize=(fh.get_width(0.3), 2))\n",
    "    plt.imshow(mean_effects.cpu().numpy().T, cmap=fh.EFFECTS_CMAP_2)\n",
    "    plt.title(\"Mean patching effects\")\n",
    "    plt.ylabel(\"Head\")\n",
    "    plt.xlabel(\"Layer\")\n",
    "    plt.colorbar(fraction=0.10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_attention_effects()\n",
    "fh.save(\"figures/attention_head_patching.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_attention_effects(mask=different_targets_mask)\n",
    "fh.save(different_targets_dir / \"attention_head_patching.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_attention_effects(mask=same_targets_mask)\n",
    "fh.save(same_targets_dir / \"attention_head_patching.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L12H12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "third_to_first_effects = torch.load(\n",
    "    \"results/L12H12/third_to_first_ablation.pt\", map_location=device\n",
    ")\n",
    "other_effects = torch.load(\"results/L12H12/other_ablation.pt\", map_location=device)\n",
    "print(third_to_first_effects.shape, other_effects.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ablation_effects(mask=None):\n",
    "    if mask is None:\n",
    "        mask = slice(None)\n",
    "\n",
    "    data = {}\n",
    "    _third_to_first_effects = third_to_first_effects[mask]\n",
    "    _other_effects = other_effects[mask]\n",
    "\n",
    "    data[r\"3rd$\\to$1st target\"] = _third_to_first_effects.cpu().numpy()\n",
    "\n",
    "    data[\"Other\"] = _other_effects.cpu().numpy()\n",
    "\n",
    "    colors = {\n",
    "        r\"3rd$\\to$1st target\": fh.COLORS[0],\n",
    "        \"Other\": fh.COLORS[-1],\n",
    "    }\n",
    "\n",
    "    fh.set()\n",
    "    return fh.plot_percentiles(\n",
    "        data,\n",
    "        zoom_start=94,\n",
    "        zoom_width_ratio=0.7,\n",
    "        colors=colors,\n",
    "        title=\"Attention ablation effects\",\n",
    "        figsize=(fh.get_width(0.66), 2),\n",
    "        tick_frequency=25,\n",
    "        zoom_tick_frequency=2,\n",
    "        y_lower=-1,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_ablation_effects()\n",
    "fh.save(\"figures/L12H12_ablation.pdf\", fig=fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_ablation_effects(mask=different_targets_mask)\n",
    "fh.save(different_targets_dir / \"L12H12_ablation.pdf\", fig=fig)\n",
    "fig = plot_ablation_effects(mask=same_targets_mask)\n",
    "fh.save(same_targets_dir / \"L12H12_ablation.pdf\", fig=fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SETTING_TO_PRETTY_NAME = {\n",
    "    \"main\": \"Probe on trained model\",\n",
    "    \"random_model\": \"Probe on random model\",\n",
    "}\n",
    "\n",
    "\n",
    "def plot_probe_results(split=\"all\"):\n",
    "    fh.set(fast=False)\n",
    "    plt.figure(figsize=(fh.HALF_WIDTH, 2))\n",
    "\n",
    "    for i, setting in enumerate([\"main\", \"random_model\"]):\n",
    "        results = np.zeros((15, 5))\n",
    "        for seed in range(5):\n",
    "            with open(f\"results/probing/{split}/{seed}/{setting}.pkl\", \"rb\") as f:\n",
    "                new_results = pickle.load(f)\n",
    "                results[:, seed] = new_results[\"accuracies\"]\n",
    "\n",
    "        means = results.mean(1)\n",
    "        squared_seed_errors = results.var(1) / results.shape[1]\n",
    "        # Size of the eval dataset is 30% of all puzzles\n",
    "        squared_acc_errors = means * (1 - means) / (0.3 * len(puzzles))\n",
    "        # 2 sigma errors\n",
    "        errors = 2 * np.sqrt(squared_seed_errors + squared_acc_errors)\n",
    "\n",
    "        max_layer = means.argmax()\n",
    "\n",
    "        print(\n",
    "            f\"Max accuracy ({setting}, L{max_layer}): {means[max_layer]:.2f} +- {errors[max_layer]:.2f}\"\n",
    "        )\n",
    "        plt.plot(\n",
    "            means,\n",
    "            label=SETTING_TO_PRETTY_NAME[setting],\n",
    "            color=fh.COLORS[i],\n",
    "            linewidth=fh.LINE_WIDTH,\n",
    "        )\n",
    "        plt.fill_between(\n",
    "            range(15),\n",
    "            means - errors,\n",
    "            means + errors,\n",
    "            color=fh.COLORS[i],\n",
    "            alpha=fh.ERROR_ALPHA,\n",
    "            linewidth=0,\n",
    "        )\n",
    "\n",
    "    plt.title(\"Third move prediction\")\n",
    "    plt.xlabel(\"Layer\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.legend()\n",
    "\n",
    "    plt.ylim(0, 1.0)\n",
    "    plt.xlim(0, 14)\n",
    "    plt.gca().spines[:].set_visible(False)\n",
    "    plt.gca().set_facecolor(fh.PLOT_FACE_COLOR)\n",
    "    plt.grid(linestyle=\"--\")\n",
    "    plt.grid(which=\"minor\", alpha=0.3, linestyle=\"--\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_probe_results()\n",
    "fh.save(\"figures/probing.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_probe_results(split=\"different_targets\")\n",
    "fh.save(different_targets_dir / \"probing.pdf\")\n",
    "plot_probe_results(split=\"same_targets\")\n",
    "fh.save(same_targets_dir / \"probing.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Piece movement heads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(knight_heads), len(bishop_heads), len(rook_heads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 4\n",
    "patterns = torch.zeros(N, 15, 24, 64, 64, device=device)\n",
    "\n",
    "boards = [LeelaBoard.from_puzzle(p) for _, p in puzzles.sample(N).iterrows()]\n",
    "\n",
    "with model.trace(boards):\n",
    "    for layer in range(15):\n",
    "        patterns[:, layer] = model.attention_scores(layer).output.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_indices = random.sample(range(64), N)\n",
    "plt.figure(figsize=(fh.HALF_WIDTH, 2))\n",
    "layer = 5\n",
    "\n",
    "layer_bishop_heads = [head for _layer, head in bishop_heads if _layer == layer]\n",
    "layer_knight_heads = [head for _layer, head in knight_heads if _layer == layer]\n",
    "layer_rook_heads = [head for _layer, head in rook_heads if _layer == layer]\n",
    "\n",
    "if not (layer_bishop_heads and layer_knight_heads and layer_rook_heads):\n",
    "    raise ValueError(\"No good heads in this layer, pick a different one\")\n",
    "\n",
    "bishop_head = random.choice(layer_bishop_heads)\n",
    "knight_head = random.choice(layer_knight_heads)\n",
    "rook_head = random.choice(layer_rook_heads)\n",
    "\n",
    "fh.set()\n",
    "\n",
    "for row, (name, head) in enumerate(\n",
    "    zip([\"Bishop\", \"Knight\", \"Rook\"], [bishop_head, knight_head, rook_head])\n",
    "):\n",
    "    for i in range(N):\n",
    "        plt.subplot(3, N, row * N + i + 1)\n",
    "        if i == 0:\n",
    "            plt.ylabel(\n",
    "                name,\n",
    "                rotation=90,\n",
    "                labelpad=10,\n",
    "                verticalalignment=\"center\",\n",
    "            )\n",
    "        plt.imshow(\n",
    "            patterns[i, layer, head, query_indices[i], :].cpu().numpy().reshape(8, 8),\n",
    "            cmap=\"Oranges\",\n",
    "        )\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "fh.save(\"figures/piece_movement_patterns.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = Path(\"results/piece_movement_heads\")\n",
    "data = torch.load(save_dir / \"effects.pt\", map_location=device)\n",
    "effects = data[\"effects\"]\n",
    "piece_movement_mask = data[\"mask\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_piece_movement_ablation(mask=None):\n",
    "    if mask is None:\n",
    "        mask = slice(None)\n",
    "    else:\n",
    "        mask = mask[piece_movement_mask]\n",
    "    data = {}\n",
    "    colors = {}\n",
    "    for i, name in enumerate([\"Main ablation\", \"Other piece types\", \"Random square\"]):\n",
    "        data[name] = effects[(\"key\", name)].squeeze().cpu().numpy()[mask]\n",
    "        colors[name] = fh.COLORS[i]\n",
    "    fh.set()\n",
    "    fh.plot_percentiles(\n",
    "        data,\n",
    "        title=\"Piece movement head ablation\",\n",
    "        colors=colors,\n",
    "        figsize=(fh.HALF_WIDTH, 2),\n",
    "        y_lower=-1,\n",
    "        tick_frequency=25,\n",
    "        y_ticks=[0, 2, 4, 6, 8],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_piece_movement_ablation()\n",
    "fh.save(\"figures/piece_movement_ablation.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_piece_movement_ablation(mask=different_targets_mask)\n",
    "fh.save(different_targets_dir / \"piece_movement_ablation.pdf\")\n",
    "plot_piece_movement_ablation(mask=same_targets_mask)\n",
    "fh.save(same_targets_dir / \"piece_movement_ablation.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Positional encodings\n",
    "These are the domain-specific positional encodings used by Leela."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "for i in range(12):\n",
    "    plt.subplot(3, 4, i + 1)\n",
    "    plt.imshow(\n",
    "        model._lc0_model.initializers.onnx_initializer_4.cpu()\n",
    "        .numpy()[0, i]\n",
    "        .reshape(8, 8)\n",
    "    )\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chess-interp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
